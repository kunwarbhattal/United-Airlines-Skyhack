{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f993b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EDA Q1: Departure Delay Summary\n",
      "| Metric                             | Value   | Unit/Context              |\n",
      "|:-----------------------------------|:--------|:--------------------------|\n",
      "| Average Departure Delay            | 21.18   | Minutes                   |\n",
      "| Flights Departing Late (Delay > 0) | 49.61%  | Percentage of All Flights |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    df_flight = pd.read_csv(\"Flight Level Data.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Flight Level Data.csv' not found. Please check your file paths.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "df_flight['scheduled_departure_datetime_local'] = pd.to_datetime(df_flight['scheduled_departure_datetime_local'], utc=True)\n",
    "df_flight['actual_departure_datetime_local'] = pd.to_datetime(df_flight['actual_departure_datetime_local'], utc=True)\n",
    "\n",
    "df_flight['departure_delay_minutes'] = (\n",
    "    df_flight['actual_departure_datetime_local'] - df_flight['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "total_flights = df_flight.shape[0]\n",
    "\n",
    "average_delay = df_flight['departure_delay_minutes'].mean()\n",
    "\n",
    "delayed_flights_count = df_flight[df_flight['departure_delay_minutes'] > 0].shape[0]\n",
    "percentage_delayed = (delayed_flights_count / total_flights) * 100\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Metric': [\n",
    "        'Average Departure Delay',\n",
    "        'Flights Departing Late (Delay > 0)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{average_delay:.2f}\",\n",
    "        f\"{percentage_delayed:.2f}%\"\n",
    "    ],\n",
    "    'Unit/Context': [\n",
    "        'Minutes',\n",
    "        'Percentage of All Flights'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_output_q1 = pd.DataFrame(data)\n",
    "\n",
    "print(\"### EDA Q1: Departure Delay Summary\")\n",
    "print(df_output_q1.to_markdown(index=False))\n",
    "\n",
    "df_flight[['company_id', 'flight_number', 'scheduled_departure_date_local', 'departure_delay_minutes', 'scheduled_ground_time_minutes', 'minimum_turn_minutes']].to_csv('temp_df_flight_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a1f28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EDA Q2: Ground Time Tightness Summary\n",
      "| Metric                                                 | Value   |   Count |\n",
      "|:-------------------------------------------------------|:--------|--------:|\n",
      "| Flights with Scheduled Ground Time  Minimum Turn Mins  | 8.05%   |     652 |\n",
      "| Flights with Scheduled Ground Time (Min Turn + 5 Mins) | 9.63%   |     780 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the flight metrics calculated in the previous step\n",
    "try:\n",
    "    df_metrics = pd.read_csv('temp_df_flight_metrics.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'temp_df_flight_metrics.csv' not found. Please run Code Block 1 first.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "df_metrics['ground_time_buffer'] = df_metrics['scheduled_ground_time_minutes'] - df_metrics['minimum_turn_minutes']\n",
    "\n",
    "total_flights = df_metrics.shape[0]\n",
    "\n",
    "tight_ground_time_count = df_metrics[df_metrics['ground_time_buffer'] <= 0].shape[0]\n",
    "percentage_tight_ground_time = (tight_ground_time_count / total_flights) * 100\n",
    "\n",
    "very_tight_ground_time_count = df_metrics[df_metrics['ground_time_buffer'] <= 5].shape[0]\n",
    "percentage_very_tight_ground_time = (very_tight_ground_time_count / total_flights) * 100\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Metric': [\n",
    "        'Flights with Scheduled Ground Time  Minimum Turn Mins',\n",
    "        'Flights with Scheduled Ground Time (Min Turn + 5 Mins)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{percentage_tight_ground_time:.2f}%\",\n",
    "        f\"{percentage_very_tight_ground_time:.2f}%\"\n",
    "    ],\n",
    "    'Count': [\n",
    "        tight_ground_time_count,\n",
    "        very_tight_ground_time_count\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_output_q2 = pd.DataFrame(data)\n",
    "\n",
    "print(\"### EDA Q2: Ground Time Tightness Summary\")\n",
    "print(df_output_q2.to_markdown(index=False))\n",
    "\n",
    "# Note: No new metrics are generated that need to be saved for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e0e219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EDA Q3: Baggage Complexity Summary\n",
      "| Metric                                         |   Value | Unit/Context                        |\n",
      "|:-----------------------------------------------|--------:|:------------------------------------|\n",
      "| Average Ratio of Transfer Bags vs. Origin Bags |  3.7458 | Ratio (Transfer Bags : Origin Bags) |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Bag Level Data\n",
    "try:\n",
    "    df_bag = pd.read_csv(\"Bag+Level+Data.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Bag+Level+Data.csv' not found. Please check your file paths.\")\n",
    "    exit()\n",
    "\n",
    "# --- Calculations ---\n",
    "\n",
    "df_bag['transfer_ind'] = df_bag['bag_type'].apply(\n",
    "    lambda x: 1 if x in ['Transfer', 'Hot Transfer'] else 0\n",
    ")\n",
    "df_bag['origin_ind'] = df_bag['bag_type'].apply(lambda x: 1 if x == 'Origin' else 0)\n",
    "\n",
    "flight_key = ['company_id', 'flight_number', 'scheduled_departure_date_local']\n",
    "df_bag_agg = df_bag.groupby(flight_key).agg(\n",
    "    transfer_bags=('transfer_ind', 'sum'),\n",
    "    origin_bags=('origin_ind', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "df_bag_agg['transfer_to_origin_ratio'] = df_bag_agg.apply(\n",
    "    lambda row: row['transfer_bags'] / row['origin_bags'] if row['origin_bags'] > 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "average_bag_ratio = df_bag_agg['transfer_to_origin_ratio'].mean()\n",
    "\n",
    "# --- Tabular Output ---\n",
    "\n",
    "data = {\n",
    "    'Metric': [\n",
    "        'Average Ratio of Transfer Bags vs. Origin Bags'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{average_bag_ratio:.4f}\"\n",
    "    ],\n",
    "    'Unit/Context': [\n",
    "        'Ratio (Transfer Bags : Origin Bags)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_output_q3 = pd.DataFrame(data)\n",
    "\n",
    "print(\"### EDA Q3: Baggage Complexity Summary\")\n",
    "print(df_output_q3.to_markdown(index=False))\n",
    "\n",
    "# Save the bag aggregation data for use in the final difficulty score calculation\n",
    "df_bag_agg.to_csv('temp_df_bag_agg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd25d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EDA Q4: Passenger Load and Delay Correlation\n",
      "| Metric                                                    |   Value | Unit/Context   |\n",
      "|:----------------------------------------------------------|--------:|:---------------|\n",
      "| Correlation: Load Factor vs. Departure Delay              | -0.1763 | Pearson R      |\n",
      "| Avg Delay for High Load Flights (Load Factor $\\geq$ 0.99) | 14.48   | Minutes        |\n",
      "| Avg Delay for Low Load Flights (Load Factor $\\leq$ 0.85)  | 37.84   | Minutes        |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    # Load metrics from previous step (Q1)\n",
    "    df_metrics = pd.read_csv('temp_df_flight_metrics.csv')\n",
    "    # Load PNR data for passenger counts\n",
    "    df_pnr_flight = pd.read_csv(\"PNR+Flight+Level+Data.csv\")\n",
    "    # Load Flight Level Data again for total_seats, as it wasn't saved in temp_df_flight_metrics.csv in Q1\n",
    "    # Re-loading df_flight directly is safer here to ensure all columns (like total_seats) are present.\n",
    "    df_flight = pd.read_csv(\"Flight Level Data.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    exit()\n",
    "\n",
    "flight_key_cols = ['company_id', 'flight_number', 'scheduled_departure_date_local']\n",
    "\n",
    "pax_key_cols = flight_key_cols + ['record_locator']\n",
    "df_pax = df_pnr_flight.groupby(pax_key_cols)['total_pax'].max().reset_index()\n",
    "df_total_pax = df_pax.groupby(flight_key_cols)['total_pax'].sum().reset_index(name='total_pax_booked')\n",
    "\n",
    "df_merged_q4 = df_flight.merge(df_total_pax, on=flight_key_cols, how='left')\n",
    "\n",
    "df_merged_q4['scheduled_departure_datetime_local'] = pd.to_datetime(df_merged_q4['scheduled_departure_datetime_local'], utc=True)\n",
    "df_merged_q4['actual_departure_datetime_local'] = pd.to_datetime(df_merged_q4['actual_departure_datetime_local'], utc=True)\n",
    "df_merged_q4['departure_delay_minutes'] = (df_merged_q4['actual_departure_datetime_local'] - df_merged_q4['scheduled_departure_datetime_local']).dt.total_seconds() / 60\n",
    "\n",
    "\n",
    "df_merged_q4['total_pax_booked'] = df_merged_q4['total_pax_booked'].fillna(0)\n",
    "df_merged_q4['load_factor'] = (df_merged_q4['total_pax_booked'] / df_merged_q4['total_seats']).clip(upper=1.0).fillna(0)\n",
    "\n",
    "load_delay_correlation = df_merged_q4['load_factor'].corr(df_merged_q4['departure_delay_minutes'])\n",
    "\n",
    "q3_load = df_merged_q4['load_factor'].quantile(0.75)\n",
    "q1_load = df_merged_q4['load_factor'].quantile(0.25)\n",
    "\n",
    "high_load_delay = df_merged_q4[df_merged_q4['load_factor'] >= q3_load]['departure_delay_minutes'].mean()\n",
    "low_load_delay = df_merged_q4[df_merged_q4['load_factor'] <= q1_load]['departure_delay_minutes'].mean()\n",
    "\n",
    "\n",
    "# --- 5. Tabular Output ---\n",
    "data = {\n",
    "    'Metric': [\n",
    "        'Correlation: Load Factor vs. Departure Delay',\n",
    "        f'Avg Delay for High Load Flights (Load Factor $\\\\geq$ {q3_load:.2f})',\n",
    "        f'Avg Delay for Low Load Flights (Load Factor $\\\\leq$ {q1_load:.2f})'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{load_delay_correlation:.4f}\",\n",
    "        f\"{high_load_delay:.2f}\",\n",
    "        f\"{low_load_delay:.2f}\"\n",
    "    ],\n",
    "    'Unit/Context': [\n",
    "        'Pearson R',\n",
    "        'Minutes',\n",
    "        'Minutes'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_output_q4 = pd.DataFrame(data)\n",
    "\n",
    "print(\"### EDA Q4: Passenger Load and Delay Correlation\")\n",
    "print(df_output_q4.to_markdown(index=False))\n",
    "\n",
    "# Save the full merged dataframe for the next step (Q5)\n",
    "df_merged_q4.to_csv('temp_df_merged_q4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814b0cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EDA Q5: SSR and Delay Analysis (Controlling for Load)\n",
      "| Metric                                    |   Value | Unit/Context      |\n",
      "|:------------------------------------------|--------:|:------------------|\n",
      "| Avg Delay for High SSR Flights (Mid Load) |   20.63 | Minutes           |\n",
      "| Avg Delay for Low SSR Flights (Mid Load)  |   13.72 | Minutes           |\n",
      "| SSR Q1 for Low SSR Classification         |    1    | Total SSRs/Flight |\n",
      "| SSR Q3 for High SSR Classification        |    3    | Total SSRs/Flight |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    # Load the intermediate file saved from the previous step (Q4)\n",
    "    df_merged_base = pd.read_csv('temp_df_merged_q4.csv')\n",
    "    df_pnr_flight = pd.read_csv(\"PNR+Flight+Level+Data.csv\")\n",
    "    df_pnr_remark = pd.read_csv(\"PNR Remark Level Data.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading files or intermediate dataframe: {e}\")\n",
    "    exit()\n",
    "\n",
    "flight_key_cols = ['company_id', 'flight_number', 'scheduled_departure_date_local']\n",
    "pnr_unique_cols = ['record_locator', 'flight_number', 'pnr_creation_date']\n",
    "\n",
    "pnr_cols_to_select = list(set(pnr_unique_cols + flight_key_cols))\n",
    "\n",
    "df_ssr_temp = df_pnr_remark.merge(\n",
    "    df_pnr_flight[pnr_cols_to_select].drop_duplicates(),\n",
    "    on=pnr_unique_cols,\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "df_ssr_counts = df_ssr_temp.groupby(flight_key_cols).size().reset_index(name='total_ssr_count')\n",
    "\n",
    "df_final = df_merged_base.merge(df_ssr_counts, on=flight_key_cols, how='left')\n",
    "df_final['total_ssr_count'] = df_final['total_ssr_count'].fillna(0)\n",
    "\n",
    "q3_load = df_final['load_factor'].quantile(0.75)\n",
    "q1_load = df_final['load_factor'].quantile(0.25)\n",
    "\n",
    "q3_ssr = df_final['total_ssr_count'].quantile(0.75)\n",
    "q1_ssr = df_final['total_ssr_count'].quantile(0.25)\n",
    "\n",
    "mid_load_df = df_final[\n",
    "    (df_final['load_factor'] > q1_load) &\n",
    "    (df_final['load_factor'] < q3_load)\n",
    "]\n",
    "\n",
    "high_ssr_delay_mid_load = mid_load_df[mid_load_df['total_ssr_count'] >= q3_ssr]['departure_delay_minutes'].mean()\n",
    "low_ssr_delay_mid_load = mid_load_df[mid_load_df['total_ssr_count'] <= q1_ssr]['departure_delay_minutes'].mean()\n",
    "\n",
    "# --- 4. Tabular Output ---\n",
    "data = {\n",
    "    'Metric': [\n",
    "        'Avg Delay for High SSR Flights (Mid Load)',\n",
    "        'Avg Delay for Low SSR Flights (Mid Load)',\n",
    "        'SSR Q1 for Low SSR Classification',\n",
    "        'SSR Q3 for High SSR Classification'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{high_ssr_delay_mid_load:.2f}\",\n",
    "        f\"{low_ssr_delay_mid_load:.2f}\",\n",
    "        f\"{q1_ssr:.1f}\",\n",
    "        f\"{q3_ssr:.1f}\"\n",
    "    ],\n",
    "    'Unit/Context': [\n",
    "        'Minutes',\n",
    "        'Minutes',\n",
    "        'Total SSRs/Flight',\n",
    "        'Total SSRs/Flight'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_output_q5 = pd.DataFrame(data)\n",
    "\n",
    "print(\"### EDA Q5: SSR and Delay Analysis (Controlling for Load)\")\n",
    "print(df_output_q5.to_markdown(index=False))\n",
    "\n",
    "# Save the final merged dataframe for the next deliverable (Difficulty Score)\n",
    "df_final.to_csv('final_merged_analysis_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598b636c",
   "metadata": {},
   "source": [
    "## Flight Difficulty Score Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8cda80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Flight Difficulty Score Generation (Robust Merge) ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'minimum_turn_minutes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'minimum_turn_minutes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     42\u001b[39m df_score[[\u001b[33m'\u001b[39m\u001b[33mtransfer_bags\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morigin_bags\u001b[39m\u001b[33m'\u001b[39m]] = df_score[[\u001b[33m'\u001b[39m\u001b[33mtransfer_bags\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morigin_bags\u001b[39m\u001b[33m'\u001b[39m]].fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# --- 4. Feature Engineering (Raw Scores - Should now succeed) ---\u001b[39;00m\n\u001b[32m     46\u001b[39m \n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# 1. Ground Time Risk: Max(0, MinTurn - SchedTime)\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# This line now uses columns guaranteed to be in df_score after the merges\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m df_score[\u001b[33m'\u001b[39m\u001b[33mtight_ground_time\u001b[39m\u001b[33m'\u001b[39m] = np.maximum(\u001b[32m0\u001b[39m, \u001b[43mdf_score\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mminimum_turn_minutes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m - df_score[\u001b[33m'\u001b[39m\u001b[33mscheduled_ground_time_minutes\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# 2. Baggage Complexity: Total bags per seat\u001b[39;00m\n\u001b[32m     52\u001b[39m df_score[\u001b[33m'\u001b[39m\u001b[33mtotal_bags_per_seat\u001b[39m\u001b[33m'\u001b[39m] = (df_score[\u001b[33m'\u001b[39m\u001b[33mtransfer_bags\u001b[39m\u001b[33m'\u001b[39m] + df_score[\u001b[33m'\u001b[39m\u001b[33morigin_bags\u001b[39m\u001b[33m'\u001b[39m]) / df_score[\u001b[33m'\u001b[39m\u001b[33mtotal_seats\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'minimum_turn_minutes'"
     ]
    }
   ],
   "source": [
    "# use K-Means or other ML algorithms to get Flight difficulty Score Development\n",
    "# make 3 clusters\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"--- Starting Flight Difficulty Score Generation (Robust Merge) ---\")\n",
    "try:\n",
    "    # Load all necessary files\n",
    "    df_analysis = pd.read_csv('final_merged_analysis_data.csv') # Contains delay, load, SSRs\n",
    "    df_bag_agg = pd.read_csv('temp_df_bag_agg.csv') # Contains bag counts\n",
    "    df_flight = pd.read_csv(\"Flight Level Data.csv\") # Original source for ground time/seats\n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR: One of the required intermediate files is missing ({e}). Cannot proceed.\")\n",
    "    exit()\n",
    "\n",
    "# Define key column set\n",
    "flight_key_cols = ['company_id', 'flight_number', 'scheduled_departure_date_local']\n",
    "\n",
    "# --- 2. Data Type Correction & Merge Preparation ---\n",
    "\n",
    "# Create a function for safe type conversion on join keys\n",
    "def cast_keys_to_str(df, keys):\n",
    "    for key in keys:\n",
    "        df[key] = df[key].astype(str)\n",
    "    return df\n",
    "\n",
    "# Prepare Flight Metrics DataFrame with necessary columns\n",
    "df_flight_metrics = df_flight[flight_key_cols + ['scheduled_ground_time_minutes', 'minimum_turn_minutes', 'total_seats']].copy()\n",
    "\n",
    "# Cast join keys to string in all primary DataFrames\n",
    "df_analysis = cast_keys_to_str(df_analysis, flight_key_cols)\n",
    "df_flight_metrics = cast_keys_to_str(df_flight_metrics, flight_key_cols)\n",
    "df_bag_agg = cast_keys_to_str(df_bag_agg, flight_key_cols)\n",
    "\n",
    "# --- 3. Final Merge ---\n",
    "\n",
    "# Merge 1: Analysis metrics (from Q5) + Flight Metrics (for ground time)\n",
    "df_score = df_analysis.merge(df_flight_metrics, on=flight_key_cols, how='left')\n",
    "\n",
    "# Merge 2: Add Bag Metrics (from Q3)\n",
    "df_score = df_score.merge(df_bag_agg[flight_key_cols + ['transfer_bags', 'origin_bags']], on=flight_key_cols, how='left')\n",
    "\n",
    "df_score[['transfer_bags', 'origin_bags']] = df_score[['transfer_bags', 'origin_bags']].fillna(0)\n",
    "\n",
    "\n",
    "# --- 4. Feature Engineering (Raw Scores - Should now succeed) ---\n",
    "\n",
    "# 1. Ground Time Risk: Max(0, MinTurn - SchedTime)\n",
    "# This line now uses columns guaranteed to be in df_score after the merges\n",
    "df_score['tight_ground_time'] = np.maximum(0, df_score['minimum_turn_minutes'] - df_score['scheduled_ground_time_minutes'])\n",
    "\n",
    "# 2. Baggage Complexity: Total bags per seat\n",
    "df_score['total_bags_per_seat'] = (df_score['transfer_bags'] + df_score['origin_bags']) / df_score['total_seats']\n",
    "df_score['total_bags_per_seat'] = df_score['total_bags_per_seat'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "# 3. Customer/SSR Complexity: SSRs per passenger\n",
    "df_score['ssr_per_pax'] = df_score['total_ssr_count'] / df_score['total_pax_booked'].replace(0, 1)\n",
    "df_score['ssr_per_pax'] = df_score['ssr_per_pax'].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "score_features = ['tight_ground_time', 'total_bags_per_seat', 'ssr_per_pax']\n",
    "\n",
    "\n",
    "# --- 5. Daily Normalization and Score Calculation ---\n",
    "\n",
    "def daily_min_max_scale(df, features):\n",
    "    for col in features:\n",
    "        min_val = df[col].min()\n",
    "        max_val = df[col].max()\n",
    "        df[f'{col}_norm'] = (df[col] - min_val) / (max_val - min_val) if (max_val - min_val) != 0 else 0\n",
    "    return df\n",
    "\n",
    "df_score = df_score.groupby('scheduled_departure_date_local', group_keys=False).apply(daily_min_max_scale, score_features)\n",
    "\n",
    "df_score['difficulty_score'] = (\n",
    "    df_score['tight_ground_time_norm'] +\n",
    "    df_score['total_bags_per_seat_norm'] +\n",
    "    df_score['ssr_per_pax_norm']\n",
    ") / len(score_features)\n",
    "\n",
    "\n",
    "# --- 6. Daily Ranking & Classification ---\n",
    "\n",
    "def classify_difficulty(df):\n",
    "    df['daily_difficulty_rank'] = df['difficulty_score'].rank(method='min', ascending=False).astype(int)\n",
    "    q_25 = df['difficulty_score'].quantile(0.25)\n",
    "    q_75 = df['difficulty_score'].quantile(0.75)\n",
    "    def classify(score):\n",
    "        if score >= q_75: return 'Difficult'\n",
    "        elif score > q_25: return 'Medium'\n",
    "        else: return 'Easy'\n",
    "    df['difficulty_classification'] = df['difficulty_score'].apply(classify)\n",
    "    return df\n",
    "\n",
    "df_final_scored = df_score.groupby('scheduled_departure_date_local', group_keys=False).apply(classify_difficulty)\n",
    "\n",
    "\n",
    "# --- 7. Output and Save ---\n",
    "\n",
    "df_deliverable = df_final_scored[[\n",
    "    'scheduled_departure_date_local', 'flight_number', 'scheduled_arrival_station_code',\n",
    "    'difficulty_score', 'daily_difficulty_rank', 'difficulty_classification'\n",
    "]].sort_values(by=['scheduled_departure_date_local', 'daily_difficulty_rank'])\n",
    "\n",
    "print(\"### Deliverable 2: Flight Difficulty Score - Top 10 Ranked Flights\")\n",
    "print(df_deliverable.head(10).to_markdown(index=False, floatfmt=\".4f\"))\n",
    "\n",
    "# Save the final scored dataframe for the next deliverable\n",
    "df_final_scored.to_csv(\"flight_difficulty_score_deliverable.csv\", index=False)\n",
    "print(\"\\nFile 'flight_difficulty_score_deliverable.csv' saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ccce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
